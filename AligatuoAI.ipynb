{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Introduction to GANs.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maha-alarifi/AIArtathon/blob/master/AligatuoAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcdnnn68DQyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m2LnmHkoNrp",
        "colab_type": "text"
      },
      "source": [
        "# Discriminative Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_xmuykWulWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, channels=1, memory=64):\n",
        "    super().__init__()\n",
        "    self.features = nn.Sequential(  # fully convolutional model\n",
        "      nn.Conv2d(channels, memory, 4, 2, 1, bias=False),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(memory, memory * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(memory * 2),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(memory * 2, memory * 4, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(memory * 4),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(memory * 4, memory * 8, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(memory * 8),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(memory * 8, 1, 4, 1, 0, bias=False),\n",
        "    )\n",
        "    # self.classifier = nn.Sequential(\n",
        "    #   nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    #   nn.Flatten(1),\n",
        "    #   nn.Sigmoid(),\n",
        "    # )\n",
        "\n",
        "  def forward(self, images):\n",
        "    # return self.classifier(self.features(images))\n",
        "    # or equivalently\n",
        "    return self.features(images).flatten(1).mean(1, keepdim=True).sigmoid()\n",
        "\n",
        "\n",
        "# the most common loss function for classification is F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOBk6cmQwoRE",
        "colab_type": "text"
      },
      "source": [
        "# Generative Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcaaO0hLGXFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_dim=100, channels=1, memory=64):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.decoder = nn.Sequential(  # fully convolutional model\n",
        "      nn.ConvTranspose2d(input_dim, memory * 8, 4, 1, 0, bias=False),\n",
        "      nn.BatchNorm2d(memory * 8),\n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(memory * 8, memory * 4, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(memory * 4),\n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(memory * 4, memory * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(memory * 2),\n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(memory * 2, memory, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(memory),\n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(memory, channels, 4, 2, 1, bias=False),\n",
        "      nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, latent_code):\n",
        "    return self.decoder(latent_code.view(-1, self.input_dim, 1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoBw3GPv2Y0h",
        "colab_type": "text"
      },
      "source": [
        "## Generative Adversarial Networks (GANs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7AOfLR7FoXG",
        "colab_type": "text"
      },
      "source": [
        "#### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "295I2teE08Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define commonly-changed training options\n",
        "dataset = '/content/shapes'  # you can put a path to image folder\n",
        "channels = 1         # RGB vs gray-scale\n",
        "batch_size = 64      # input batch size\n",
        "\n",
        "z_dim = 100          # size of the latent z vector\n",
        "image_size = 64      # the height / width of the input image\n",
        "capacity_d = 64      # size factor (memory) for the discriminator\n",
        "capacity_g = 64      # size factor (memory) for the generator\n",
        "\n",
        "epochs = 25          # number of epochs\n",
        "lr = 0.0002          # learning rate for the optimizer (Adam)\n",
        "beta1 = 0.5          # Adam beta1: exponential decay rate for the 1st moment\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJmVuMQbFsvw",
        "colab_type": "text"
      },
      "source": [
        "#### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3UnH_-nJKYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the dataset and initialize the data loader\n",
        "def get_dataset(dataset, image_size=image_size, channels=channels):\n",
        "  Dataset = ImageFolder\n",
        "  directory = Path(dataset)\n",
        "  return Dataset(directory, transform=transforms.Compose([\n",
        "           transforms.Resize(image_size),\n",
        "           transforms.CenterCrop(image_size),\n",
        "           transforms.Grayscale(),\n",
        "           transforms.ToTensor(),\n",
        "           transforms.Normalize([0.5] * channels, [0.5] * channels),\n",
        "         ]))\n",
        "\n",
        "data_loader = DataLoader(get_dataset(dataset), batch_size,\n",
        "                         shuffle=True, drop_last=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZzXN5UFh09f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image_grid(images, columns=8, ax=None, show=True):\n",
        "  if ax is None:\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "  image_grid = make_grid(images.detach().cpu(), columns, normalize=True)\n",
        "  ax.imshow(image_grid.permute(1, 2, 0), interpolation='nearest')\n",
        "  ax.axis('off')\n",
        "  if show:\n",
        "    plt.show(ax.figure)\n",
        "  return ax\n",
        "\n",
        "_ = plot_image_grid(next(iter(data_loader))[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJoPUmCwFwcx",
        "colab_type": "text"
      },
      "source": [
        "#### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNariRr9PQ7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the discriminator (net_d) and the generator (net_g)\n",
        "net_d = Discriminator(channels, memory=capacity_d).to(device)\n",
        "net_g = Generator(z_dim, channels, memory=capacity_g).to(device)\n",
        "\n",
        "# setup an optimizer for each model\n",
        "optimizer_d = Adam(net_d.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_g = Adam(net_g.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# create fixed noise, to track generator progress, and labels\n",
        "fixed_noise = torch.randn(batch_size, z_dim, device=device)\n",
        "real_label = torch.ones(batch_size, 1, device=device)\n",
        "fake_label = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "# define how you would like the progress to be printed\n",
        "states = []   # save the state of our GAN after each epoch\n",
        "metrics = []  # metrics to monitor\n",
        "def progress(log):\n",
        "  total = len(log['loss/gen'])\n",
        "  err_g = sum(log['loss/gen']) / total\n",
        "  err_d_real = sum(log['loss/d_real']) / total\n",
        "  err_d_fake = sum(log['loss/d_fake']) / total\n",
        "  d_x = sum(log['score/d_real']) / total\n",
        "  d_g_z1 = sum(log['score/d_fake']) / total\n",
        "  d_g_z2 = sum(log['score/gen']) / total\n",
        "  return (f'\\rLoss_D: {err_d_real + err_d_fake:.4f} Loss_G: {err_g:.4f} '\n",
        "          f'D(x): {d_x:.4f} D(G(z)): {d_g_z1:.4f} / {d_g_z2:.4f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVyHR0zHF-YR",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic1U_sMLPXI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze(images, labels, binary_classifier):\n",
        "  scores = binary_classifier(images)  # values in [0, 1]\n",
        "  loss = F.binary_cross_entropy(scores, labels)\n",
        "  if loss.requires_grad:\n",
        "    loss.backward()  # compute gradients\n",
        "  return float(loss), float(scores.detach().mean())\n",
        "\n",
        "# start training\n",
        "for epoch in range(len(metrics), epochs):\n",
        "  print(f'Epoch [{epoch}/{epochs - 1}]')\n",
        "  net_g.train(True)\n",
        "  log = defaultdict(list)\n",
        "  metrics.append(log)\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # sample real (from dataset) and fake (using net_g) images\n",
        "    real = data[0].to(device)  # real images\n",
        "    fake = net_g(torch.randn(real.size(0), z_dim, device=device))\n",
        "    fake_detached = fake.detach()\n",
        "\n",
        "    # train the dicriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "    optimizer_d.zero_grad()\n",
        "    err_d_real, d_x = analyze(real, real_label, net_d)\n",
        "    err_d_fake, d_g_z1 = analyze(fake_detached, fake_label, net_d)\n",
        "    optimizer_d.step()  # learn\n",
        "    \n",
        "    # train the generator: maximize log(D(G(z)))\n",
        "    optimizer_g.zero_grad()\n",
        "    err_g, d_g_z2 = analyze(fake, real_label, net_d)\n",
        "    optimizer_g.step()  # learn\n",
        "\n",
        "    ##############################################################\n",
        "\n",
        "    # record the metrics\n",
        "    log['loss/d_real'].append(err_d_real)\n",
        "    log['loss/d_fake'].append(err_d_fake)\n",
        "    log['loss/gen'].append(err_g)\n",
        "    log['score/d_real'].append(d_x)        # D(x)\n",
        "    log['score/d_fake'].append(d_g_z1)     # D(G(z_1))\n",
        "    log['score/gen'].append(d_g_z2)        # D(G(z_2))\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      print(progress(log), end='')\n",
        "\n",
        "  # display progress with few examples after every epoch\n",
        "  print(progress(log))\n",
        "  with torch.no_grad():\n",
        "    net_g.train(False)\n",
        "    epoch_samples = net_g(fixed_noise)\n",
        "  ax = plot_image_grid(epoch_samples)\n",
        "  # ax.figure.savefig(f'./samples_{epoch:03d}.png')\n",
        "\n",
        "  # save your progress in a checkpoint (optional)\n",
        "  state = {\n",
        "      'log': log,\n",
        "      'epoch': epoch,\n",
        "      'net_d': net_d.state_dict(),\n",
        "      'net_g': net_g.state_dict(),\n",
        "      'opt_d': optimizer_d.state_dict(),\n",
        "      'opt_g': optimizer_g.state_dict(),\n",
        "  }\n",
        "  # torch.save(state, f'./gan_{epoch:03d}.pth')\n",
        "  states.append(state)\n",
        "  if len(states) > 3:  # keep only the last 3 states\n",
        "    states.pop(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm7v50bdPyfm",
        "colab_type": "text"
      },
      "source": [
        "*See also: [PyTorch-Lightning](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxuI1ljZGQta",
        "colab_type": "text"
      },
      "source": [
        "#### Play with It"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNgpGCIws9yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# every time you run this, you will plot new randomly generated samples\n",
        "with torch.no_grad():\n",
        "  net_g.train(False)\n",
        "  z = torch.randn(batch_size, z_dim, device=device)\n",
        "  plot_image_grid(net_g(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTXNHLziHFcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title interpolate between images { run: \"auto\" }\n",
        "seed = 42 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "num_pairs = 8\n",
        "num_interpolations = 7\n",
        "def interpolate(x, y, count=num_interpolations):\n",
        "  alphas = torch.linspace(0, 1, count, device=x.device)\n",
        "  out = torch.stack([(1 - a) * x + a * y for a in alphas])\n",
        "  return out.permute(1, 0, 2).contiguous()\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "z_1 = torch.randn(num_pairs, z_dim, device=device)\n",
        "z_2 = torch.randn(num_pairs, z_dim, device=device)\n",
        "with torch.no_grad():\n",
        "  net_g.train(False)\n",
        "  plot_image_grid(net_g(interpolate(z_1, z_2)), columns=num_interpolations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt1DyzXNXICR",
        "colab_type": "text"
      },
      "source": [
        "### GAN Loss visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL7cYDOfXPvv",
        "colab_type": "text"
      },
      "source": [
        "<button disabled><img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/07/Line-Plots-of-Loss-and-Accuracy-for-a-Generative-Adversarial-Network-with-Mode-Collapse.png\" width=\"600\"></button>\n",
        "<h5><i><b>Source:</b> <a href=\"https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/\">Jason Brownlee</a></i></h5>\n",
        "\n",
        "GANs suffer from [**problems**](https://developers.google.com/machine-learning/gan/problems) like vanishing gradients, mode collapse, and failure to converge. [Patience and deep understanding](https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/) are required.  \n",
        "[**Here**](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628), is a quick ~10 minutes read that nicely summarizes ten things to keep in mind when training GANs by Marco Pasini.  \n",
        "You might also be interested in reading \"[Stabilizing GAN Training: A Survey](https://arxiv.org/abs/1910.00927)\" by Maciej Wiatrak and Stefano Albrecht.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ4Ya_b1uLIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chunk_size = 100\n",
        "\n",
        "def smooth(values, chunk_size=chunk_size):  # 1d non-overlapping conv\n",
        "  if chunk_size <= 1:\n",
        "    return values\n",
        "  out = []\n",
        "  for i in range(len(values) // chunk_size):\n",
        "    chunk = values[i * chunk_size: (i + 1) * chunk_size]\n",
        "    out.append(sum(chunk) / len(chunk))\n",
        "  return out\n",
        "\n",
        "plot = {}\n",
        "for k in metrics[0]:\n",
        "  plot[k] = smooth([x for m in metrics for x in m[k]])\n",
        "\n",
        "x = torch.linspace(0, epochs - 1, len(plot['loss/gen'])).tolist()\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(x, plot['loss/d_real'], label='loss/d_real')\n",
        "plt.plot(x, plot['loss/d_fake'], label='loss/d_fake')\n",
        "plt.plot(x, plot['loss/gen'], label='loss/gen')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(x, plot['score/d_real'], label='score/d_real')\n",
        "plt.plot(x, plot['score/d_fake'], label='score/d_fake')\n",
        "plt.plot(x, plot['score/gen'], label='score/gen')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HazDVmjSTEjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}